import pandas as pd
import sys
from sklearn.model_selection import train_test_split
from pipeline.preprocessing_pipeline import PreprocessingPipeline

def split_data(X, y, employee_col='employee_id', date_col='date'):
    """×—×œ×•×§×” ×¢× ××™×•×Ÿ ×œ×¤×™ ×¢×•×‘×“ ×•×ª××¨×™×š ×¢×‘×•×¨ """    
    # ×¦×•×¨ DataFrame ×××•×—×“ ×œ××™×•×Ÿ
    combined_df = pd.concat([X, y], axis=1)
    
    # ××™×™×Ÿ ×œ×¤×™ employee_id ×•××– ×œ×¤×™ date
    if employee_col in combined_df.columns and date_col in combined_df.columns:
        combined_df = combined_df.sort_values(by=[employee_col, date_col])
        print(f"Data sorted by {employee_col} and {date_col}")
    elif employee_col in combined_df.columns:
        combined_df = combined_df.sort_values(by=employee_col)
        print(f"Data sorted by {employee_col} only (date column not found)")
    else:
        print(f"Warning: Employee column '{employee_col}' not found. Using original order.")
    
    # ×¤×¦×œ ×‘×—×–×¨×” ×œ-X ×•-y
    X_sorted = combined_df.drop(columns=[y.name])
    y_sorted = combined_df[y.name]
    
    n_samples = len(X_sorted)
    
    # ×—×œ×•×§×” ×–×× ×™×ª: 60% ×˜×¨×™×™×Ÿ, 20% ×•×œ×™×“×™×™×©×Ÿ, 20% ×˜×¡×˜
    train_end = int(0.6 * n_samples)
    val_end = int(0.8 * n_samples)
    
    X_train = X_sorted.iloc[:train_end]
    X_val = X_sorted.iloc[train_end:val_end]
    X_test = X_sorted.iloc[val_end:]
    
    y_train = y_sorted.iloc[:train_end]
    y_val = y_sorted.iloc[train_end:val_end]
    y_test = y_sorted.iloc[val_end:]
    
    return X_train, X_val, X_test, y_train, y_val, y_test

def main():
            
    df = pd.read_csv('insider_threat_dataset.csv')
    print(f"Original dataset size: {len(df)} records")
        
    # ×”××¨×” ×œfloat32 ×›×“×™ ×œ×—×¡×•×š ×–×™×›×¨×•×Ÿ
    df = df.astype({col: 'float32' for col in df.select_dtypes(include=['float64']).columns})
        
    # ×”×¡×¨ ×¢××•×“×•×ª ×©×œ× ×¨×œ×•×•× ×˜×™×•×ª
    columns_to_drop = [col for col in ['is_emp_malicious', 'modification_details'] if col in df.columns]
    if columns_to_drop:
        df = df.drop(columns=columns_to_drop)
        print(f"Dropped columns: {columns_to_drop}")
    
    # ×”×›×Ÿ ××ª ×”×“××˜×” ×œ×¢×™×‘×•×“
    target_col = 'is_malicious'
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    print(f"\nPreparing X and y...")
    print(f"X shape: {X.shape}")
    print(f"y shape: {y.shape}")
        
    pipeline = PreprocessingPipeline()
    
    # ×××Ÿ ××ª ×”×¤×™×™×¤×œ×™×™×Ÿ ×¢×œ ×›×œ ×”×“××˜×” (×¨×§ fit, ×œ× transform ×¢×“×™×™×Ÿ)
    print("\nğŸ”§ FITTING pipeline...")
    pipeline.fit(X, y)
    print("âœ… Pipeline fit completed!")
        
    # ×”×—×œ ××ª ×”×¤×™×™×¤×œ×™×™×Ÿ ×¢×œ ×›×œ ×”×“××˜×”
    print("\nğŸ”„ TRANSFORMING data...")
    X_processed = pipeline.transform(X)
    print("âœ… Pipeline transform completed!")
                    
    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_processed, y)
    
    print(f"\nDataset split sizes after preprocessing and cleaning:")
    print(f"Train: {len(X_train)} samples ({len(X_train)/len(X_processed)*100:.1f}%)")
    print(f"Validation: {len(X_val)} samples ({len(X_val)/len(X_processed)*100:.1f}%)")
    print(f"Test: {len(X_test)} samples ({len(X_test)/len(X_processed)*100:.1f}%)")
    
    # ×”×›×Ÿ DataFrames ×¢× ×”×˜×¨×’×˜
    train_df = pd.concat([
        X_train.reset_index(drop=True), 
        y_train.reset_index(drop=True)
    ], axis=1)

    val_df = pd.concat([
        X_val.reset_index(drop=True), 
        y_val.reset_index(drop=True)
    ], axis=1)

    test_df = pd.concat([
        X_test.reset_index(drop=True), 
        y_test.reset_index(drop=True)
    ], axis=1)
    
    # ×©××•×¨ ×§×‘×¦×™ CSV
    train_filename = 'train_processed.csv'
    val_filename = 'val_processed.csv'
    test_filename = 'test_processed.csv'
    
    train_df.to_csv(train_filename, index=False)
    val_df.to_csv(val_filename, index=False)
    test_df.to_csv(test_filename, index=False)
    
    print(f"\nFinal processed dataset shapes:")
    print(f"Train shape: {train_df.shape}")
    print(f"Validation shape: {val_df.shape}")
    print(f"Test shape: {test_df.shape}")
    
    # ×‘×“×•×§ ××ª ×”×ª×¤×œ×’×•×ª ×”×˜×¨×’×˜ ×‘×›×œ ×¡×˜
    print(f"\nTarget distribution:")
    print(f"Train - Positive: {y_train.sum()}/{len(y_train)} ({y_train.mean()*100:.2f}%)")
    print(f"Val - Positive: {y_val.sum()}/{len(y_val)} ({y_val.mean()*100:.2f}%)")
    print(f"Test - Positive: {y_test.sum()}/{len(y_test)} ({y_test.mean()*100:.2f}%)")
    
    print(f"\nFiles saved:")
    print(f"- {train_filename}") 
    print(f"- {val_filename}")
    print(f"- {test_filename}")

if __name__ == '__main__':
    main()